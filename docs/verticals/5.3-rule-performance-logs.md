# Vertical 5.3: Rule Performance & Logs

> **Domain:** Governance & Meta (observability for parsers, normalizers, rules)
> **Additions:** Parser execution metrics, normalization rule performance, queue depth tracking, error rates
> **Status:** ✅ Complete
> **Last Updated:** 2025-10-25

---

## 1. What Problem Does This Solve?

**User Story:**
> "As a **platform engineer**, I need to monitor parser execution times, normalization rule performance, and queue depths so I can identify bottlenecks, optimize slow rules, and ensure the system processes documents within SLA targets."

**Without this vertical:**
- ❌ No visibility into which parsers are slow or failing frequently
- ❌ No way to identify inefficient normalization rules causing processing delays
- ❌ No tracking of queue depths to detect backlog buildup
- ❌ No error rate monitoring to detect systemic issues (e.g., parser bugs, data quality problems)
- ❌ No historical performance trends to guide optimization efforts
- ❌ No alerting when processing times exceed SLA thresholds
- ❌ No ability to correlate performance issues with specific document types or data patterns

**With this vertical:**
- ✅ Real-time metrics for parser execution (latency p50/p95/p99, success rate, error types)
- ✅ Normalization rule performance tracking (execution time per rule, match rate, error rate)
- ✅ Queue depth monitoring (documents pending, in-progress, stuck/retrying)
- ✅ Error rate dashboards with grouping by parser, rule, error type
- ✅ Historical trend analysis (performance over time, degradation detection)
- ✅ Automated alerting (SLA breaches, error spikes, queue backlog)
- ✅ Performance drill-down (slowest parsers, inefficient rules, failed batches)

**Impact:**
- **Operational Excellence:** Proactive issue detection before users report problems
- **Performance Optimization:** Data-driven decisions on which parsers/rules to optimize
- **SLA Compliance:** Monitor and enforce processing time targets (e.g., <35s p95 for parsing)
- **Cost Efficiency:** Identify resource-intensive operations for optimization or scaling

---

## 2. Core Capabilities

### 2.1 Parser Execution Metrics

Track detailed metrics for every parser execution:

```typescript
const metrics = await MetricsCollector.recordParserExecution({
  parser_id: "bofa_pdf_v2",
  upload_id: "upl_abc123",
  started_at: "2025-10-25T10:00:00Z",
  completed_at: "2025-10-25T10:00:12Z",
  status: "success",
  observations_extracted: 47,
  pages_processed: 3,
  error_type: null
});

// Metrics stored:
// - Duration: 12 seconds
// - Success rate: 100%
// - Observations per second: 3.92
// - Pages per second: 0.25
```

**Aggregated Metrics (per parser):**
- Latency percentiles: p50, p95, p99 (e.g., "bofa_pdf_v2: p95 = 18.2s")
- Success rate: % of executions that completed successfully
- Error rate: % of executions that failed (grouped by error type)
- Throughput: Observations extracted per second
- Volume: Total documents processed (last 24h, 7d, 30d)

**Example Query:**
```typescript
const stats = await PerformanceAnalyzer.getParserStats({
  parser_id: "bofa_pdf_v2",
  time_range: "24h"
});

// Returns:
{
  executions: 1247,
  success_rate: 0.982,
  latency_p50: 9.8,
  latency_p95: 18.2,
  latency_p99: 24.7,
  error_breakdown: {
    "pdf_corrupted": 12,
    "timeout": 5,
    "out_of_memory": 1
  },
  observations_per_second: 4.1
}
```

### 2.2 Normalization Rule Performance

Track execution time and effectiveness for each normalization rule:

```typescript
const ruleMetrics = await MetricsCollector.recordRuleExecution({
  rule_id: "merchant_normalize_starbucks",
  observation_id: "obs_xyz789",
  started_at: "2025-10-25T10:00:15.200Z",
  completed_at: "2025-10-25T10:00:15.235Z",
  matched: true,
  transformation_applied: true,
  error: null
});

// Metrics stored:
// - Execution time: 35ms
// - Match rate: 100% (rule matched)
// - Transformation applied: Yes
```

**Aggregated Metrics (per rule):**
- Execution time percentiles: p50, p95, p99 (e.g., "regex rules slower than exact match")
- Match rate: % of observations where rule matched
- Transformation success rate: % of matches where transformation succeeded
- Error rate: % of executions that threw errors
- Impact: % of observations affected by this rule

**Example Query:**
```typescript
const ruleStats = await PerformanceAnalyzer.getRuleStats({
  rule_id: "merchant_normalize_starbucks",
  time_range: "7d"
});

// Returns:
{
  executions: 8923,
  match_rate: 0.87,
  avg_execution_time_ms: 28.5,
  p95_execution_time_ms: 42.0,
  transformation_success_rate: 1.0,
  errors: 0,
  observations_affected: 7763
}
```

**Slowest Rules Report:**
```typescript
const slowRules = await PerformanceAnalyzer.getSlowestRules({
  time_range: "24h",
  limit: 10
});

// Returns:
[
  {
    rule_id: "merchant_fuzzy_match_all",
    rule_type: "fuzzy",
    avg_execution_time_ms: 145.2,
    p95_execution_time_ms: 280.5,
    executions: 12456,
    recommendation: "Consider exact match rules first, fuzzy as fallback"
  },
  // ... top 9 slowest rules
]
```

### 2.3 Queue Depth Monitoring

Track document processing queue metrics in real-time:

```typescript
const queueMetrics = await QueueMonitor.getQueueDepth({
  queue: "parse_queue",
  timestamp: "2025-10-25T10:00:00Z"
});

// Returns:
{
  pending: 145,          // Documents waiting to be processed
  in_progress: 12,       // Documents currently being processed
  stuck: 3,              // Documents stuck in retry loop (>5 failures)
  oldest_pending_age_seconds: 42,
  avg_wait_time_seconds: 18.5,
  processing_rate_per_minute: 45.2
}
```

**Queue Health Indicators:**
- **Backlog Alert:** Pending > 500 documents (indicates insufficient processing capacity)
- **Stuck Documents:** Documents with >5 retry attempts (likely data quality or parser bugs)
- **Stale Queue:** Oldest pending document >5 minutes old (processing stalled)
- **Throughput Drop:** Processing rate <30 docs/min (below SLA target)

**Multi-Queue Monitoring:**
```typescript
const allQueues = await QueueMonitor.getAllQueues();

// Returns:
{
  parse_queue: {
    pending: 145,
    in_progress: 12,
    stuck: 3,
    health: "warning" // pending > threshold
  },
  normalize_queue: {
    pending: 87,
    in_progress: 8,
    stuck: 0,
    health: "healthy"
  },
  reconcile_queue: {
    pending: 234,
    in_progress: 15,
    stuck: 12,
    health: "critical" // stuck > threshold
  }
}
```

### 2.4 Error Rate Dashboards

Track and visualize error rates across parsers, rules, and queues:

```typescript
const errorStats = await ErrorAnalyzer.getErrorBreakdown({
  time_range: "24h",
  group_by: "parser_id"
});

// Returns:
{
  total_errors: 142,
  error_rate: 0.018, // 1.8% of all executions
  breakdown: [
    {
      parser_id: "bofa_pdf_v2",
      error_count: 52,
      error_types: {
        "pdf_corrupted": 32,
        "timeout": 15,
        "out_of_memory": 5
      },
      total_executions: 1247,
      error_rate: 0.042 // 4.2%
    },
    {
      parser_id: "chase_csv_v1",
      error_count: 90,
      error_types: {
        "invalid_format": 78,
        "missing_columns": 12
      },
      total_executions: 2893,
      error_rate: 0.031 // 3.1%
    }
  ]
}
```

**Error Trend Analysis:**
```typescript
const errorTrend = await ErrorAnalyzer.getErrorTrend({
  parser_id: "bofa_pdf_v2",
  time_range: "7d",
  granularity: "1h"
});

// Returns time series:
[
  { timestamp: "2025-10-19T00:00:00Z", error_count: 2, error_rate: 0.015 },
  { timestamp: "2025-10-19T01:00:00Z", error_count: 1, error_rate: 0.008 },
  // ... spike detected
  { timestamp: "2025-10-20T14:00:00Z", error_count: 28, error_rate: 0.187 },
  // ... back to normal
  { timestamp: "2025-10-20T15:00:00Z", error_count: 3, error_rate: 0.021 }
]
```

### 2.5 Historical Trend Analysis

Track performance trends over time to detect degradation:

```typescript
const performanceTrend = await TrendAnalyzer.getPerformanceTrend({
  parser_id: "bofa_pdf_v2",
  metric: "latency_p95",
  time_range: "30d",
  granularity: "1d"
});

// Returns:
{
  current_value: 18.2,
  baseline_value: 12.5, // 30 days ago
  trend: "degrading",
  degradation_percentage: 45.6,
  anomalies: [
    {
      date: "2025-10-15",
      value: 32.4,
      deviation: 2.5, // 2.5 standard deviations above baseline
      likely_cause: "deployment of bofa_pdf_v2.1 (reverted same day)"
    }
  ]
}
```

**Capacity Planning:**
```typescript
const capacityForecast = await TrendAnalyzer.forecastCapacity({
  queue: "parse_queue",
  current_processing_rate: 45.2, // docs/min
  projected_volume_growth: 0.15, // 15% monthly growth
  forecast_horizon_days: 90
});

// Returns:
{
  current_capacity_utilization: 0.68, // 68%
  projected_utilization_90d: 0.94,
  capacity_breach_date: "2025-12-20", // When utilization > 90%
  recommendation: "Scale workers by 30% before 2025-12-15 to maintain <80% utilization"
}
```

---

## 3. User Workflows

### Workflow 1: Identify Slow Parser

**Persona:** Platform Engineer

**Steps:**
1. Open Performance Dashboard
2. Select "Parser Performance" tab
3. Sort by "Latency P95" descending
4. Identify parser "bofa_pdf_v2" with p95 = 32.4s (SLA breach: >30s)
5. Drill down to see:
   - Recent executions (sample of slowest 10)
   - Document size distribution (larger PDFs = slower)
   - Error types (timeouts correlated with large files)
6. Recommendation: Increase timeout from 30s to 45s for large PDFs
7. Create ticket to optimize parser (investigate memory leaks, optimize regex patterns)

### Workflow 2: Optimize Slow Normalization Rule

**Persona:** Data Engineer

**Steps:**
1. Open Performance Dashboard
2. Select "Rule Performance" tab
3. View "Slowest Rules" report
4. Identify rule "merchant_fuzzy_match_all" with p95 = 280.5ms
5. Analyze rule:
   - Type: Fuzzy matching (Levenshtein distance across 15,000 merchants)
   - Match rate: 12% (low - only matches 12% of observations)
   - Total time spent: 1.8 hours/day across all executions
6. Optimization:
   - Add exact match rules for top 100 merchants (covers 80% of volume)
   - Use fuzzy match only as fallback (reduces executions by 80%)
7. Deploy optimized ruleset
8. Monitor performance: p95 drops to 45ms (84% improvement)

### Workflow 3: Investigate Queue Backlog

**Persona:** DevOps Engineer

**Steps:**
1. Receive alert: "Parse queue depth > 500 (critical threshold)"
2. Open Queue Monitor dashboard
3. Observe:
   - Pending: 847 documents
   - In-progress: 12 documents (normal)
   - Stuck: 45 documents (abnormal - usually <10)
   - Processing rate: 18 docs/min (below target of 45 docs/min)
4. Drill down to stuck documents:
   - All stuck documents are from parser "chase_csv_v1"
   - Error type: "invalid_format" (recent Chase bank format change)
5. Immediate action:
   - Pause queue for "chase_csv_v1" documents
   - Update parser to handle new format
   - Redeploy parser
   - Resume queue
6. Result: Backlog clears in 30 minutes, processing rate returns to 45 docs/min

### Workflow 4: Detect Performance Degradation

**Persona:** SRE Engineer

**Steps:**
1. Weekly performance review meeting
2. Open Trend Analysis dashboard
3. Observe parser "bofa_pdf_v2" latency p95 increasing:
   - 30 days ago: 12.5s
   - Today: 18.2s (+45.6% degradation)
4. Investigate correlation:
   - Check deployment history: No recent parser changes
   - Check document volume: Volume increased 22% (within expected range)
   - Check document characteristics: Average PDF size increased from 1.2 MB to 2.8 MB (+133%)
5. Root cause: Users uploading higher-resolution scanned PDFs (large file sizes)
6. Solution:
   - Implement PDF compression pipeline before parsing (reduce file size by 60%)
   - Increase parser worker memory allocation (4 GB → 6 GB)
7. Deploy changes
8. Result: Latency p95 returns to 13.1s (within SLA)

---

## 4. Data Model

### 4.1 ParserExecutionMetric

Stores metrics for each parser execution:

```sql
CREATE TABLE parser_execution_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  parser_id VARCHAR(255) NOT NULL,
  upload_id VARCHAR(255) NOT NULL,
  started_at TIMESTAMPTZ NOT NULL,
  completed_at TIMESTAMPTZ,
  duration_ms INTEGER, -- Computed: (completed_at - started_at) in milliseconds
  status VARCHAR(50) NOT NULL, -- success | error | timeout
  observations_extracted INTEGER,
  pages_processed INTEGER,
  error_type VARCHAR(100),
  error_message TEXT,
  document_size_bytes BIGINT,
  created_at TIMESTAMPTZ DEFAULT NOW(),

  INDEX idx_parser_started (parser_id, started_at),
  INDEX idx_status_started (status, started_at),
  INDEX idx_duration (duration_ms) WHERE status = 'success'
);
```

### 4.2 RuleExecutionMetric

Stores metrics for each normalization rule execution:

```sql
CREATE TABLE rule_execution_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  rule_id VARCHAR(255) NOT NULL,
  rule_type VARCHAR(50) NOT NULL, -- exact | regex | fuzzy | soundex
  observation_id VARCHAR(255) NOT NULL,
  started_at TIMESTAMPTZ NOT NULL,
  completed_at TIMESTAMPTZ,
  execution_time_ms INTEGER, -- Computed: (completed_at - started_at) in milliseconds
  matched BOOLEAN NOT NULL,
  transformation_applied BOOLEAN,
  error_type VARCHAR(100),
  error_message TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),

  INDEX idx_rule_started (rule_id, started_at),
  INDEX idx_rule_type_started (rule_type, started_at),
  INDEX idx_execution_time (execution_time_ms) WHERE matched = true
);
```

### 4.3 QueueDepthSnapshot

Stores queue depth snapshots (taken every 60 seconds):

```sql
CREATE TABLE queue_depth_snapshots (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  queue_name VARCHAR(100) NOT NULL,
  snapshot_at TIMESTAMPTZ NOT NULL,
  pending INTEGER NOT NULL,
  in_progress INTEGER NOT NULL,
  stuck INTEGER NOT NULL,
  oldest_pending_age_seconds INTEGER,
  avg_wait_time_seconds DECIMAL(10, 2),
  processing_rate_per_minute DECIMAL(10, 2),
  health_status VARCHAR(50) NOT NULL, -- healthy | warning | critical

  INDEX idx_queue_snapshot (queue_name, snapshot_at)
);
```

### 4.4 ErrorLog

Stores detailed error information:

```sql
CREATE TABLE error_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  occurred_at TIMESTAMPTZ NOT NULL,
  error_type VARCHAR(100) NOT NULL,
  error_message TEXT,
  stack_trace TEXT,
  context JSONB, -- { parser_id, upload_id, rule_id, observation_id }
  severity VARCHAR(50) NOT NULL, -- low | medium | high | critical
  resolved_at TIMESTAMPTZ,
  resolution_notes TEXT,

  INDEX idx_occurred_type (occurred_at, error_type),
  INDEX idx_context_parser ((context->>'parser_id')),
  INDEX idx_unresolved (resolved_at) WHERE resolved_at IS NULL
);
```

---

## 5. API Contracts

### 5.1 Record Parser Execution Metric

```typescript
POST /api/metrics/parser-execution

Request:
{
  "parser_id": "bofa_pdf_v2",
  "upload_id": "upl_abc123",
  "started_at": "2025-10-25T10:00:00Z",
  "completed_at": "2025-10-25T10:00:12Z",
  "status": "success",
  "observations_extracted": 47,
  "pages_processed": 3,
  "document_size_bytes": 2458624,
  "error_type": null,
  "error_message": null
}

Response (201 Created):
{
  "id": "pem_xyz789",
  "duration_ms": 12000,
  "created_at": "2025-10-25T10:00:13Z"
}
```

### 5.2 Get Parser Performance Stats

```typescript
GET /api/metrics/parser-stats?parser_id=bofa_pdf_v2&time_range=24h

Response (200 OK):
{
  "parser_id": "bofa_pdf_v2",
  "time_range": "24h",
  "executions": 1247,
  "success_rate": 0.982,
  "latency_p50": 9.8,
  "latency_p95": 18.2,
  "latency_p99": 24.7,
  "error_breakdown": {
    "pdf_corrupted": 12,
    "timeout": 5,
    "out_of_memory": 1
  },
  "observations_per_second": 4.1,
  "avg_document_size_mb": 1.8,
  "throughput_docs_per_hour": 51.9
}
```

### 5.3 Get Slowest Rules

```typescript
GET /api/metrics/slowest-rules?time_range=24h&limit=10

Response (200 OK):
{
  "time_range": "24h",
  "rules": [
    {
      "rule_id": "merchant_fuzzy_match_all",
      "rule_type": "fuzzy",
      "avg_execution_time_ms": 145.2,
      "p95_execution_time_ms": 280.5,
      "executions": 12456,
      "match_rate": 0.12,
      "total_time_spent_hours": 1.8,
      "recommendation": "Consider exact match rules first, fuzzy as fallback"
    },
    // ... top 9 slowest rules
  ]
}
```

### 5.4 Get Queue Depth

```typescript
GET /api/metrics/queue-depth?queue=parse_queue

Response (200 OK):
{
  "queue_name": "parse_queue",
  "snapshot_at": "2025-10-25T10:00:00Z",
  "pending": 145,
  "in_progress": 12,
  "stuck": 3,
  "oldest_pending_age_seconds": 42,
  "avg_wait_time_seconds": 18.5,
  "processing_rate_per_minute": 45.2,
  "health_status": "healthy",
  "alerts": []
}
```

### 5.5 Get Error Breakdown

```typescript
GET /api/metrics/error-breakdown?time_range=24h&group_by=parser_id

Response (200 OK):
{
  "time_range": "24h",
  "total_errors": 142,
  "error_rate": 0.018,
  "breakdown": [
    {
      "parser_id": "bofa_pdf_v2",
      "error_count": 52,
      "error_types": {
        "pdf_corrupted": 32,
        "timeout": 15,
        "out_of_memory": 5
      },
      "total_executions": 1247,
      "error_rate": 0.042
    },
    // ... other parsers
  ]
}
```

---

## 6. Performance Targets

**Parser Execution Metrics:**
- Metric ingestion latency: <10ms (p95) to record metric after parser completes
- Query latency (single parser stats): <50ms (p95)
- Query latency (all parsers stats): <200ms (p95)
- Data retention: 90 days hot (PostgreSQL), 2 years warm (S3 parquet)

**Normalization Rule Metrics:**
- Metric ingestion latency: <5ms (p95) to record metric after rule executes
- Query latency (single rule stats): <30ms (p95)
- Query latency (slowest rules report): <150ms (p95)
- Data retention: 30 days hot, 1 year warm

**Queue Depth Monitoring:**
- Snapshot frequency: Every 60 seconds
- Alert latency: <30 seconds from breach detection to alert sent
- Query latency (current queue depth): <20ms (p95)
- Data retention: 7 days hot, 90 days warm

**Error Logging:**
- Error ingestion latency: <5ms (p95)
- Query latency (error breakdown): <100ms (p95)
- Full-text search latency: <500ms (p95)
- Data retention: 90 days hot, 1 year warm (compliance)

**Dashboard Rendering:**
- Initial dashboard load: <1.5s (includes 4 panels: parser stats, rule stats, queue depth, error breakdown)
- Chart rendering (time series with 7 days of hourly data): <800ms
- Drill-down query (slowest executions for specific parser): <300ms

---

## 7. Edge Cases

**Edge Case 1: Parser Execution Never Completes**
- **Scenario:** Parser process crashes before recording completion
- **Detection:** `completed_at` remains NULL after 5 minutes
- **Resolution:** Background job marks as "timeout" after 5 minutes, creates error log

**Edge Case 2: Clock Skew in Distributed System**
- **Scenario:** `completed_at` < `started_at` due to clock skew
- **Detection:** Negative duration computed
- **Resolution:** Use server-side timestamps only (ignore client timestamps), log warning

**Edge Case 3: Zero Observations Extracted**
- **Scenario:** Parser completes successfully but extracts 0 observations (empty document)
- **Impact:** `observations_per_second` = 0, but success rate = 100%
- **Resolution:** Track separately as "empty_document" status (not error, not normal success)

**Edge Case 4: Queue Depth Snapshot During Deploy**
- **Scenario:** Queue workers restart during snapshot, causing temporary spike in "stuck" count
- **Resolution:** Apply 3-sample moving average to smooth out deployment spikes

**Edge Case 5: Rule Executed Multiple Times for Same Observation**
- **Scenario:** Observation re-normalized due to manual correction or re-parsing
- **Impact:** Duplicate metrics for same observation_id
- **Resolution:** Include `normalization_run_id` to distinguish between runs

**Edge Case 6: Historical Data Deleted (GDPR)**
- **Scenario:** User deletion triggers cascade delete of observations, orphaning metrics
- **Impact:** Metrics reference non-existent `observation_id`
- **Resolution:** Store observation_id as opaque string (don't use foreign key), preserve metrics even after observation deletion (anonymized)

**Edge Case 7: Metric Ingestion Backlog**
- **Scenario:** High throughput (1000 docs/sec) causes metric ingestion lag
- **Impact:** Real-time dashboards show stale data (5 minutes delay)
- **Resolution:** Buffer metrics in Redis queue, batch insert to PostgreSQL (1000 metrics per insert), show "Last updated: 2 minutes ago" indicator on dashboard

**Edge Case 8: Time Zone Confusion**
- **Scenario:** Parser executes in UTC, but dashboard shows local time (PST)
- **Impact:** Trends appear shifted by 8 hours
- **Resolution:** Store all timestamps in UTC (TIMESTAMPTZ), convert to user's local time in UI only

---

## 8. Security & Privacy

**Access Control:**
- **Metrics Read:** Platform engineers, SRE engineers, data engineers (view-only)
- **Metrics Write:** System services only (parser coordinators, normalization engine)
- **Alert Configuration:** Platform engineers only (create/edit alert rules)
- **Data Export:** Platform engineers + compliance team (for audits)

**Data Sensitivity:**
- **Low Sensitivity:** Aggregate metrics (p95 latency, error counts) - no PII
- **Medium Sensitivity:** Individual execution metrics (contains upload_id, observation_id) - indirect PII linkage
- **High Sensitivity:** Error messages (may contain snippets of user data in stack traces)

**Data Retention:**
- **Aggregate Metrics:** Retained indefinitely (no PII)
- **Individual Execution Metrics:** Anonymize after 90 days (remove upload_id, observation_id)
- **Error Logs:** Scrub PII from error messages before storage, redact sensitive fields

**Compliance:**
- **GDPR:** Metrics not directly tied to user identity, but `upload_id` can be linked to user
- **HIPAA:** Error messages must not contain PHI (patient names, SSNs, medical record numbers)
- **SOX:** Performance metrics retained for 7 years for audit purposes (aggregate only)

---

## 9. Monitoring & Alerting

**SLA Alerts (Critical):**
- Parser latency p95 > 30s for >5 minutes (SLA breach)
- Normalization latency p95 > 5s for >5 minutes (SLA breach)
- Queue depth > 500 pending documents (capacity issue)
- Error rate > 5% for any parser (systemic issue)

**Capacity Alerts (Warning):**
- Queue depth > 200 pending documents for >10 minutes (approaching capacity)
- Processing rate < 30 docs/min for >5 minutes (throughput degradation)
- Stuck documents > 20 (parser bugs or data quality issues)

**Anomaly Alerts (Info):**
- Parser latency p95 increases >50% compared to 7-day baseline (performance degradation)
- Error rate doubles compared to previous 24h (investigate root cause)
- New error type appears for first time (unknown failure mode)

**Alert Delivery:**
- Critical: PagerDuty (wakes on-call engineer)
- Warning: Slack #platform-alerts channel
- Info: Daily digest email to platform team

**Alert Suppression:**
- During deployments (maintenance window): Suppress capacity alerts for 15 minutes
- Known issues (e.g., Chase format change): Suppress specific error type alerts until parser updated

---

## 10. Integration Points

**Upstream (Data Sources):**
- **ParserCoordinator:** Sends parser execution metrics after each parse operation
- **NormalizationEngine:** Sends rule execution metrics after each normalization
- **QueueWorker:** Sends queue depth snapshots every 60 seconds
- **ErrorHandler:** Sends error logs for all unhandled exceptions

**Downstream (Data Consumers):**
- **Performance Dashboard:** Queries aggregated metrics for visualization
- **Alerting Service:** Polls metrics every 60s to evaluate alert rules
- **Capacity Planning Tool:** Queries historical trends for forecasting
- **Incident Response System:** Links error logs to incidents for root cause analysis

**External Integrations:**
- **DataDog / Prometheus:** Export metrics to external monitoring (StatsD protocol)
- **PagerDuty:** Send critical alerts to on-call rotation
- **Slack:** Post warning alerts to #platform-alerts channel
- **S3:** Archive old metrics (>90 days) to S3 parquet files for long-term storage

---

## 11. OL Primitives (Objective Layer)

### MetricsCollector
**Purpose:** Record execution metrics for parsers and rules with minimal overhead
**Methods:**
- `recordParserExecution(params)` → `Promise<MetricID>` - Record parser execution with latency, status, observations extracted
- `recordRuleExecution(params)` → `Promise<MetricID>` - Record rule execution with match status, execution time
- `recordQueueSnapshot(params)` → `Promise<SnapshotID>` - Record queue depth snapshot (pending, in-progress, stuck)
- `recordError(params)` → `Promise<ErrorID>` - Record error with context, severity, stack trace

**Multi-Domain Applicability:** Finance (parser metrics), Healthcare (HL7 processor metrics), Legal (document OCR metrics), Research (data ingestion metrics), E-commerce (product import metrics), SaaS (webhook delivery metrics)

### PerformanceAnalyzer
**Purpose:** Query and aggregate metrics for analysis and dashboards
**Methods:**
- `getParserStats(params)` → `Promise<ParserStats>` - Get aggregated stats for specific parser (latency percentiles, success rate, error breakdown)
- `getRuleStats(params)` → `Promise<RuleStats>` - Get aggregated stats for specific rule (execution time, match rate, transformation success rate)
- `getSlowestRules(params)` → `Promise<RuleStats[]>` - Get top N slowest rules for optimization
- `getErrorBreakdown(params)` → `Promise<ErrorBreakdown>` - Get error counts grouped by parser/rule/error type

**Multi-Domain Applicability:** Finance (transaction processing stats), Healthcare (claim processing stats), Legal (document processing stats), Research (data pipeline stats), E-commerce (order processing stats), SaaS (API endpoint stats)

### QueueMonitor
**Purpose:** Monitor queue depths and detect backlog/stuck documents
**Methods:**
- `getQueueDepth(queue)` → `Promise<QueueDepth>` - Get current queue depth (pending, in-progress, stuck)
- `getAllQueues()` → `Promise<Map<QueueName, QueueDepth>>` - Get depth for all queues
- `getStuckDocuments(queue)` → `Promise<Document[]>` - Get list of stuck documents with retry counts
- `getProcessingRate(queue, interval)` → `Promise<number>` - Get processing rate (docs/min) over last N minutes

**Multi-Domain Applicability:** Finance (transaction queue), Healthcare (claim processing queue), Legal (document review queue), Research (data ingestion queue), E-commerce (order fulfillment queue), SaaS (background job queue)

### TrendAnalyzer
**Purpose:** Analyze historical trends and detect performance degradation
**Methods:**
- `getPerformanceTrend(params)` → `Promise<Trend>` - Get metric trend over time (detect degradation, anomalies)
- `getErrorTrend(params)` → `Promise<Trend>` - Get error rate trend over time (detect spikes)
- `forecastCapacity(params)` → `Promise<CapacityForecast>` - Forecast when capacity will be breached based on current trends
- `detectAnomalies(params)` → `Promise<Anomaly[]>` - Detect anomalies in metrics (standard deviation > 2.5)

**Multi-Domain Applicability:** Finance (fraud detection trends), Healthcare (patient volume trends), Legal (case load trends), Research (data growth trends), E-commerce (order volume trends), SaaS (API usage trends)

---

## 12. IL Components (Interface Layer)

### PerformanceDashboard
**Purpose:** Real-time dashboard showing parser, rule, queue, and error metrics
**Props:** `timeRange` (24h | 7d | 30d), `refreshInterval` (60s default), `filters` (parser_id, rule_id)
**Panels:**
- Parser Performance (latency p95, success rate, top 5 parsers by volume)
- Rule Performance (slowest rules, match rates, execution time distribution)
- Queue Health (depth chart, processing rate, stuck documents count)
- Error Breakdown (error counts by type, trend chart, recent errors list)

**Multi-Domain Applicability:** Finance (transaction processing dashboard), Healthcare (claim processing dashboard), Legal (document processing dashboard), Research (data pipeline dashboard), E-commerce (order processing dashboard), SaaS (API performance dashboard)

### RuleOptimizer
**Purpose:** UI for identifying and optimizing slow normalization rules
**Props:** `timeRange` (7d | 30d), `ruleType` (exact | regex | fuzzy), `sortBy` (execution_time | match_rate)
**Features:**
- List slowest rules with execution time percentiles
- Drill-down to see sample executions (slowest 10)
- Recommendations (e.g., "Use exact match before fuzzy")
- Test rule changes (simulate performance impact)

**Multi-Domain Applicability:** Finance (merchant normalization), Healthcare (diagnosis code mapping), Legal (document classification rules), Research (data cleansing rules), E-commerce (product categorization rules), SaaS (data transformation rules)

### QueueMonitorPanel
**Purpose:** Real-time queue depth monitoring with health indicators
**Props:** `queues` (list of queue names), `refreshInterval` (30s default), `alertThresholds` (pending, stuck)
**Features:**
- Queue depth chart (pending, in-progress, stuck) over time
- Health status badges (healthy | warning | critical)
- Processing rate trend (docs/min)
- Stuck documents drill-down (view stuck items, retry manually)

**Multi-Domain Applicability:** Finance (payment processing queue), Healthcare (lab result queue), Legal (e-discovery queue), Research (data ingestion queue), E-commerce (order queue), SaaS (webhook delivery queue)

---

## 13. Reusability Across Domains

The Rule Performance & Logs vertical is a **universal observability pattern** applicable to ANY domain with document processing pipelines:

**Finance Domain:**
- Parser metrics: Bank statement parsing (PDF, CSV, OFX)
- Rule metrics: Merchant normalization, transaction categorization
- Queue monitoring: Parse queue, normalize queue, reconcile queue
- Error tracking: PDF corruption, format changes, timeout issues

**Healthcare Domain:**
- Parser metrics: HL7 message parsing, FHIR resource processing, medical record OCR
- Rule metrics: Diagnosis code mapping (ICD-9 → ICD-10), patient matching rules
- Queue monitoring: Claim processing queue, lab result ingestion queue
- Error tracking: Invalid HL7 segments, missing required fields, duplicate patient records

**Legal Domain:**
- Parser metrics: Contract OCR, case document extraction, e-discovery processing
- Rule metrics: Document classification rules (contract type, jurisdiction), entity extraction rules
- Queue monitoring: Document review queue, OCR processing queue
- Error tracking: OCR accuracy issues, missing pages, corrupted scans

**Research Domain:**
- Parser metrics: Research paper extraction (PDF, XML), dataset parsing (CSV, JSON, NetCDF)
- Rule metrics: Citation extraction rules, metadata normalization rules
- Queue monitoring: Data ingestion queue, citation processing queue
- Error tracking: Invalid DOIs, missing abstracts, encoding issues

**E-commerce Domain:**
- Parser metrics: Product catalog import (CSV, XML, API), supplier data feeds
- Rule metrics: Product categorization rules, price normalization rules
- Queue monitoring: Product import queue, image processing queue
- Error tracking: Invalid SKUs, missing images, pricing errors

**SaaS Domain:**
- Parser metrics: Webhook payload parsing, API request processing, user data import
- Rule metrics: Data transformation rules (customer fields), validation rules
- Queue monitoring: Background job queue, webhook delivery queue
- Error tracking: Invalid JSON, rate limit errors, third-party API failures

**Insurance Domain:**
- Parser metrics: Claims form extraction (PDF, image), policy document parsing
- Rule metrics: Policy number validation rules, coverage calculation rules
- Queue monitoring: Claims processing queue, underwriting queue
- Error tracking: Missing policy numbers, invalid claim amounts, duplicate claims

---

## 14. Pattern Abstraction

The Rule Performance & Logs vertical implements a **universal observability pattern** for data pipelines:

**Abstract Pattern:**
```
ANY document/data processing system requires:

1. Execution Metrics:
   - Record start/end timestamps for each processing unit (parser, rule, job)
   - Compute latency percentiles (p50, p95, p99)
   - Track success rate, error rate, throughput

2. Performance Analysis:
   - Identify slow processing units (slowest parsers, slowest rules)
   - Drill down to specific executions (sample slowest 10)
   - Provide optimization recommendations

3. Queue Monitoring:
   - Track queue depth (pending, in-progress, stuck)
   - Monitor processing rate (items/min)
   - Alert on backlog buildup or processing stalls

4. Error Tracking:
   - Log errors with context (parser_id, rule_id, document_id)
   - Group errors by type, severity
   - Track error trends over time

5. Trend Analysis:
   - Detect performance degradation (compare to baseline)
   - Forecast capacity needs (predict when capacity breached)
   - Identify anomalies (standard deviation > 2.5)
```

**Generic Implementation:**
```typescript
interface MetricsCollector<T> {
  recordExecution(params: ExecutionParams<T>): Promise<MetricID>;
  recordError(error: Error, context: T): Promise<ErrorID>;
}

interface PerformanceAnalyzer<T> {
  getStats(id: string, timeRange: TimeRange): Promise<Stats>;
  getSlowestUnits(limit: number): Promise<UnitStats[]>;
  getErrorBreakdown(groupBy: keyof T): Promise<ErrorBreakdown>;
}

interface QueueMonitor {
  getQueueDepth(queue: string): Promise<QueueDepth>;
  getProcessingRate(queue: string): Promise<number>;
  getStuckItems(queue: string): Promise<Item[]>;
}

interface TrendAnalyzer {
  getPerformanceTrend(metric: string, timeRange: TimeRange): Promise<Trend>;
  detectAnomalies(metric: string): Promise<Anomaly[]>;
  forecastCapacity(queue: string): Promise<CapacityForecast>;
}
```

**Instantiation Examples:**
- Finance: `T = { parser_id, upload_id, rule_id, observation_id }`
- Healthcare: `T = { processor_id, message_id, rule_id, patient_id }`
- Legal: `T = { ocr_engine_id, document_id, rule_id, case_id }`
- Research: `T = { extractor_id, paper_id, rule_id, dataset_id }`

---

## 15. Testing Strategy

**Unit Tests:**
- `MetricsCollector.recordParserExecution()` stores metrics correctly
- `PerformanceAnalyzer.getParserStats()` computes percentiles accurately
- `QueueMonitor.getQueueDepth()` returns correct counts
- `TrendAnalyzer.detectAnomalies()` identifies outliers (z-score > 2.5)

**Integration Tests:**
- End-to-end metric recording: Parser execution → metric stored → query returns correct stats
- Queue depth monitoring: Simulate queue backlog → alert triggered within 30s
- Error tracking: Simulate parser error → error log created → error breakdown updated

**Performance Tests:**
- Metric ingestion throughput: 10,000 metrics/sec (batch insert)
- Query latency: <50ms p95 for single parser stats
- Dashboard rendering: <1.5s for initial load (4 panels)

**Load Tests:**
- High throughput: 1,000 parser executions/sec → metrics ingested with <100ms lag
- Concurrent queries: 100 simultaneous dashboard users → <200ms p95 query latency

---

## 16. Security Considerations

**Authentication:**
- All metrics API endpoints require authentication (JWT token)
- Metrics write endpoints restricted to system services only (API key)

**Authorization:**
- Platform engineers: Full read access to all metrics
- Data engineers: Read access to rule performance metrics only
- External auditors: Read access to aggregate metrics only (no individual execution details)

**Data Encryption:**
- Metrics stored unencrypted (no PII in aggregate metrics)
- Error logs encrypted at rest (may contain sensitive data in error messages)
- Metrics in transit encrypted via HTTPS

**Audit Trail:**
- All metrics queries logged (who, when, what query)
- Alert configuration changes logged (who, when, what changed)
- Data exports logged (who, when, what data exported)

---

## 17. Performance Characteristics

**Write Performance:**
- Metric ingestion: <10ms p95 (single metric insert)
- Batch ingestion: 10,000 metrics/sec (batch insert via COPY)
- Queue snapshot: <5ms (insert single row)

**Read Performance:**
- Single parser stats: <50ms p95 (aggregate query with WHERE parser_id)
- All parsers stats: <200ms p95 (aggregate query across all parsers)
- Slowest rules report: <150ms p95 (aggregate + ORDER BY + LIMIT 10)
- Queue depth (current): <20ms p95 (single row query with ORDER BY snapshot_at DESC LIMIT 1)
- Error breakdown: <100ms p95 (GROUP BY error_type)

**Storage:**
- Metrics growth: ~10 KB per parser execution (includes metadata)
- Retention: 90 days hot = ~800 GB (100K executions/day * 90 days * 10 KB)
- Archive: 2 years warm = ~7 TB compressed (S3 parquet)

**Indexing:**
- Index on (parser_id, started_at): Speeds up time-range queries for specific parser
- Index on (status, started_at): Speeds up error queries
- Index on (duration_ms): Speeds up slowest execution queries

---

## 18. Observability

**Metrics to Monitor (Meta-Observability):**
- Metric ingestion lag: <100ms p95 (time between execution completion and metric stored)
- Query latency: <50ms p95 (dashboard queries)
- Error log ingestion lag: <50ms p95
- Queue snapshot frequency: Every 60s ±5s

**Logging:**
- All metrics API requests logged (endpoint, params, duration, status)
- Alert evaluations logged (rule_id, triggered: true/false, timestamp)
- Anomaly detections logged (metric, value, deviation)

**Dashboards:**
- Metrics System Health Dashboard (meta-dashboard):
  - Metric ingestion rate (metrics/sec)
  - Query latency (p50, p95, p99)
  - Error log ingestion rate (errors/sec)
  - Alert evaluation latency (time to evaluate all rules)

**Alerts:**
- Metric ingestion lag > 500ms for >5 minutes (system overload)
- Query latency > 500ms for >5 minutes (database performance issue)
- Alert evaluation lag > 2 minutes (alerting service down)

---

## 19. Deployment & Operations

**Deployment:**
- Deploy as separate microservice (metrics-service) for isolation
- Use PostgreSQL with TimescaleDB extension for time-series optimization
- Redis queue for buffering high-throughput metric ingestion
- Auto-scaling: Scale workers based on Redis queue depth (>1000 queued metrics → add worker)

**Database Migrations:**
- Create tables with indexes (parser_execution_metrics, rule_execution_metrics, queue_depth_snapshots, error_logs)
- Create partitions for time-series tables (monthly partitions for metrics)
- Create materialized views for common aggregate queries (daily parser stats)

**Monitoring:**
- Monitor metrics service health (CPU, memory, query latency)
- Monitor PostgreSQL performance (connection pool, slow queries)
- Monitor Redis queue depth (should be near 0 under normal load)

**Backup:**
- PostgreSQL: Daily full backup, hourly incremental
- S3 archive: Redundant storage (3 copies across regions)

**Disaster Recovery:**
- RPO (Recovery Point Objective): 1 hour (worst case: lose 1 hour of metrics)
- RTO (Recovery Time Objective): 15 minutes (restore from backup)

---

## 20. Future Enhancements

**Phase 1 (Current):**
- ✅ Basic metrics collection (parser, rule, queue, error)
- ✅ Performance dashboard (aggregate stats, trends)
- ✅ SLA alerting (latency breaches, error spikes)

**Phase 2 (Q1 2026):**
- 🔄 Anomaly detection with machine learning (predict issues before SLA breach)
- 🔄 Root cause analysis (correlate errors with deployments, data patterns)
- 🔄 Capacity forecasting (predict when to scale infrastructure)

**Phase 3 (Q2 2026):**
- 🔄 Distributed tracing (trace single document through entire pipeline)
- 🔄 Cost attribution (track compute cost per parser, per rule)
- 🔄 A/B testing framework (compare performance of parser versions)

**Phase 4 (Q3 2026):**
- 🔄 Predictive optimization (auto-tune rule order based on performance data)
- 🔄 Self-healing (auto-restart stuck workers, auto-scale on backlog)
- 🔄 Multi-region aggregation (consolidate metrics across regions for global view)

---

## Conclusion

Vertical 5.3 provides **comprehensive observability** for document processing pipelines, enabling platform teams to monitor performance, detect issues, optimize slow operations, and ensure SLA compliance. The pattern is universally applicable across Finance, Healthcare, Legal, Research, E-commerce, SaaS, and Insurance domains—anywhere data pipelines process documents, messages, or transactions at scale.
