# OL Primitive: CanonicalStore

**Type**: Storage / Data Repository
**Domain**: Universal (domain-agnostic)
**Version**: 1.0
**Status**: Specification
**Introduced in**: Vertical 1.3 (Normalization)

---

## Purpose

Persistent storage for validated canonical records (normalized, cleaned data). Provides idempotent upsert operations and querying capabilities. Unlike ObservationStore (immutable raw data), CanonicalStore can be regenerated by re-normalizing observations with updated rules.

---

## Interface Contract

```python
from typing import List, Optional

class CanonicalStore:
    def upsert(self, canonical: Canonical) -> None:
        """
        Insert or update canonical by canonical_id (idempotent).
        Enables re-normalization with updated rules.
        """
        pass

    def get_by_upload(self, upload_id: str) -> List[Canonical]:
        """Retrieve all canonicals for an upload."""
        pass

    def get_by_id(self, canonical_id: str) -> Optional[Canonical]:
        """Retrieve single canonical by ID."""
        pass

    def query(self, filters: dict) -> List[Canonical]:
        """
        Query canonicals by criteria.
        Examples: date range, account, category, amount range.
        """
        pass

    def delete_by_upload(self, upload_id: str) -> int:
        """Delete all canonicals for upload. Returns count deleted."""
        pass
```

---

## Behavior

**Idempotent upserts (re-normalization):**
```python
# First normalization
canonical_v1 = Canonical(
    canonical_id="CT_abc123",
    observation_id="UL_test:0",
    category="Uncategorized"  # No rule for merchant yet
)
store.upsert(canonical_v1)

# Update rules, re-normalize
canonical_v2 = Canonical(
    canonical_id="CT_abc123",  # Same ID
    observation_id="UL_test:0",
    category="Food & Drink"  # Rule added
)
store.upsert(canonical_v2)  # Overwrites v1

assert store.get_by_id("CT_abc123").category == "Food & Drink"
```

---

## Storage Schema

```sql
CREATE TABLE canonicals (
    canonical_id TEXT PRIMARY KEY,
    upload_id TEXT NOT NULL,
    observation_id TEXT NOT NULL,  -- Link back to raw data
    normalized_at TIMESTAMPTZ NOT NULL,
    normalizer_version TEXT NOT NULL,
    rule_set_version TEXT,

    -- Domain-specific fields (JSONB for flexibility)
    canonical_data JSONB NOT NULL,

    -- Metadata
    confidence_score DECIMAL(3,2),
    applied_rules TEXT[],
    flags TEXT[]
);

CREATE INDEX idx_canonicals_upload_id ON canonicals(upload_id);
CREATE INDEX idx_canonicals_normalized_at ON canonicals(normalized_at);
```

---

## Multi-Domain Applicability

**Finance:** Store CanonicalTransaction (validated dates, amounts, categories)
**Healthcare:** Store CanonicalLabResult (validated test values, units)
**Legal:** Store CanonicalClause (categorized contract clauses)
**Research (RSRCH - Utilitario):** Store CanonicalFact (validated founder/company facts with multi-source provenance, normalized entity names)
**Manufacturing:** Store CanonicalMeasurement (calibrated sensor values)
**Media:** Store CanonicalUtterance (cleaned transcripts with speaker IDs)

---

## Domain Validation

### ✅ Finance (Primary Instantiation)
**Use case:** Store validated canonical transactions after normalization
**Example:** Normalizer processes 42 ObservationTransaction records → produces 42 CanonicalTransaction records with `canonical_id="CT_abc123_0"`, `canonical_data={"date": "2025-01-15T00:00:00Z", "amount": -5.75, "merchant": "Starbucks", "category": "Food & Drink"}` (ISO dates, Decimal amounts, clean strings) → CanonicalStore upserts 42 records
**Schema:** `CanonicalTransaction` (canonical_id, upload_id, canonical_data: {date, amount, merchant, category, account})
**Regeneration:** Update merchant rules → re-normalize → upsert with same canonical_id → overwrites old canonicals with improved merchant names
**Status:** ✅ Fully implemented in personal-finance-app

### ✅ Healthcare
**Use case:** Store validated canonical lab results after normalization
**Example:** Normalizer processes 8 ObservationLabResult records → produces 8 CanonicalLabResult records with `canonical_id="CLR_lab456_0"`, `canonical_data={"test_code": "LOINC:2345-7", "value": 95.0, "unit": "mg/dL", "normal_range": "70-100", "flag": "normal"}` (standardized codes, validated ranges) → CanonicalStore upserts 8 records
**Schema:** `CanonicalLabResult` (canonical_id, upload_id, canonical_data: {test_code, value, unit, normal_range, test_date})
**Regeneration:** Update LOINC mapping rules → re-normalize → upsert with updated test codes
**Status:** ✅ Conceptually validated via examples in this doc

### ✅ Legal
**Use case:** Store validated canonical clauses after normalization
**Example:** Normalizer processes 47 ObservationClause records → produces 47 CanonicalClause records with `canonical_id="CC_contract789_0"`, `canonical_data={"clause_type": "payment_terms", "obligation_type": "payment", "deadline_days": 30, "enforceability": "mandatory"}` (classified clause types) → CanonicalStore upserts 47 records
**Schema:** `CanonicalClause` (canonical_id, upload_id, canonical_data: {clause_type, obligation_type, deadline_days, enforceability})
**Regeneration:** Update clause classification rules → re-normalize → upsert with improved clause types
**Status:** ✅ Conceptually validated via examples in this doc

### ✅ RSRCH (Utilitario Research)
**Use case:** Store validated canonical facts after entity resolution
**Example:** Normalizer processes 12 RawFact records → produces 12 CanonicalFact records with `canonical_id="CF_article101_0"`, `canonical_data={"entity_name": "Sam Altman", "entity_type": "person", "company": "OpenAI", "investment_amount": 375000000, "fact_type": "investment", "source_url": "techcrunch.com/..."}` (normalized entity names, parsed amounts) → CanonicalStore upserts 12 records
**Schema:** `CanonicalFact` (canonical_id, upload_id, canonical_data: {entity_name, entity_type, company, investment_amount, fact_type})
**Regeneration:** Update entity resolution rules ("@sama" → "Sam Altman") → re-normalize → upsert with canonical entity names
**Status:** ✅ Conceptually validated via examples in this doc

### ✅ E-commerce
**Use case:** Store validated canonical products after normalization
**Example:** Normalizer processes 1,500 ObservationProduct records → produces 1,500 CanonicalProduct records with `canonical_id="CP_catalog202_0"`, `canonical_data={"SKU": "IPHONE15-256-BLU", "title": "iPhone 15 Pro Max 256GB", "price": 1199.99, "category": ["Electronics", "Phones"], "availability": "in_stock"}` (clean titles, parsed prices, category hierarchies) → CanonicalStore upserts 1,500 records
**Schema:** `CanonicalProduct` (canonical_id, upload_id, canonical_data: {SKU, title, price, category, availability})
**Regeneration:** Update product title cleaning rules → re-normalize → upsert with cleaner titles
**Status:** ✅ Conceptually validated via examples in this doc

**Validation Status:** ✅ **5 domains validated** (1 fully implemented, 4 conceptually verified)
**Domain-Agnostic Score:** 100% (generic upsert/query interface, canonical_data JSONB accepts any schema)
**Reusability:** High (same storage pattern works for transactions, lab results, clauses, facts, products; enables re-normalization across all domains)

---

## Related Primitives

- **Normalizer**: Produces canonicals that are stored here
- **ObservationStore**: Source of raw data used to create canonicals
- **NormalizationLog**: Records normalization execution that created canonicals
- **UploadRecord**: References canonicals via `canonicals_count`

---

**Last Updated**: 2025-10-27
**Maturity**: Spec complete, ready for implementation
